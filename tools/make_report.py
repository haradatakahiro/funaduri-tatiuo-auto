from __future__ import annotations

import re
from pathlib import Path
from datetime import timedelta
from collections import Counter

import numpy as np
import pandas as pd

# ===== è¨­å®š =====
SRC = Path("data/funaduri_daily.xlsx")      # å…ƒãƒ‡ãƒ¼ã‚¿Excel
SHEET_CANDIDATES = ["all_fish", "allfish"] # ã‚·ãƒ¼ãƒˆåã‚†ã‚Œå¯¾ç­–
SHEET_KASHI = "kashimamaru"                # é¹¿å³¶ä¸¸ã‚·ãƒ¼ãƒˆåï¼ˆrun_daily.py ã§ä½œæˆï¼‰
OUT_MD = Path("reports/report.md")

# ä»»æ„ï¼šæ—¥æ¬¡é›†è¨ˆã‚’ãŸã‚ã‚‹ï¼ˆé•·æœŸé‹ç”¨ã§ä¾¿åˆ©ï¼‰
HISTORY_CSV = Path("history/daily_metrics.csv")

WINDOW_MONTH = 30
WINDOW_YEAR = 365

# TOP5ã®å¯¾è±¡ã«ã™ã‚‹æœ€å°éš»æ•°ï¼ˆé­šç¨®å†…æ¯”è¼ƒãŒæˆç«‹ã™ã‚‹ç¯„å›²ï¼‰
MIN_RECORDS_FOR_TOP5 = 3

# ã€Œã‚¿ãƒã‚¦ã‚ªã€ã¨ã¿ãªã™é­šç¨®åï¼ˆå¿…è¦ãªã‚‰è¿½åŠ ï¼‰
TACHIUO_NAMES = {"ã‚¿ãƒã‚¦ã‚ª", "å¤ªåˆ€é­š"}


# =========================================================
# Xè¡¨è¨˜ã®æ‰±ã„ï¼ˆä»•æ§˜ï¼‰
# - 1æ¡ã® "X" ã¯ 0 æ‰±ã„ï¼ˆä¿å®ˆçš„ï¼‰
# - 2æ¡ã® "1X" ã¯ 15ï¼ˆ10ã€œ19ã®ä¸­å¤®å€¤ï¼‰, "2X" ã¯ 25 ...
# - å°æ•°ã® "0.4X" ã¯ 0.45ï¼ˆ0.40ã€œ0.49ã®ä¸­å¤®å€¤ï¼‰
# - ãƒ¬ãƒ³ã‚¸ "0-1X" ã¯ä¸¡ç«¯ã‚’ä¸Šã®ãƒ«ãƒ¼ãƒ«ã§æ•°å€¤åŒ–ã—ã¦ (min,max) ã‚’ä½œã‚‹
# - è¡¨ç¤ºã¯ã€Œä¸­å¤®å€¤ï¼ˆ(min+max)/2ï¼‰ã€ã®å˜å€¤ã‚’åŸºæœ¬ã«ã™ã‚‹
# =========================================================

def _x_token_to_value(token: str) -> float | None:
    """
    token: 'X', '1X', '2X', '0.4X', '12', '3.5' ãªã©
    è¿”ã‚Šå€¤: æ•°å€¤åŒ–ã§ãã‚Œã°floatã€ã§ããªã‘ã‚Œã°None
    """
    t = token.strip()
    if not t:
        return None

    # å°æ•°+Xï¼šä¾‹ 0.4X -> 0.45
    m = re.fullmatch(r"(\d+)\.(\d)X", t)
    if m:
        return float(f"{m.group(1)}.{m.group(2)}5")

    # 1æ¡ Xï¼šä¾‹ X -> 0
    if t == "X":
        return 0.0

    # 2æ¡ Xï¼šä¾‹ 1X -> 15, 2X -> 25
    m = re.fullmatch(r"(\d)X", t)
    if m:
        return float(int(m.group(1)) * 10 + 5)

    # é€šå¸¸ã®æ•°å€¤
    m = re.fullmatch(r"\d+(?:\.\d+)?", t)
    if m:
        return float(t)

    return None


def _pre_normalize(s: str) -> str:
    """
    æ–‡å­—ã®ã‚†ã‚Œã‚’è»½ãçµ±ä¸€ï¼ˆãƒ¬ãƒ³ã‚¸è¨˜å·ã ã‘ï¼‰ã€‚
    Xã¯æ„å‘³ãŒã‚ã‚‹ã®ã§æ¶ˆã•ãªã„ã€‚
    """
    s = s.strip()
    s = s.replace("ï¼", "-").replace("â€”", "-").replace("â€•", "-")
    s = s.replace("ã€œ", "-").replace("ï½", "-")
    return s


def parse_range(val) -> tuple[float, float]:
    """ '18-40 å°¾' / '45cm' / 'X-4 æ¯' / '0-1X æœ¬' / '0.4Xkg' ãªã©ã‚’ (min, max) ã« """
    if pd.isna(val):
        return (np.nan, np.nan)

    s = str(val).strip()
    if s in {"", "ï¼", "-", "â€”", "â€•"}:
        return (np.nan, np.nan)

    s = _pre_normalize(s)

    # ãƒ¬ãƒ³ã‚¸ï¼ˆA-Bï¼‰ã‚’ã¾ãšæ¢ã™ï¼ˆå˜ä½ã¯å¾Œã‚ã«ä»˜ãã®ã§ç„¡è¦–ï¼‰
    # A/B ã¯ 'X', '1X', '0.4X', '12', '3.5' ãªã©ã‚’è¨±å®¹
    m = re.search(
        r"(?P<a>(?:\d+\.\dX)|(?:\dX)|X|(?:\d+(?:\.\d+)?))\s*-\s*(?P<b>(?:\d+\.\dX)|(?:\dX)|X|(?:\d+(?:\.\d+)?))",
        s,
    )
    if m:
        a = _x_token_to_value(m.group("a"))
        b = _x_token_to_value(m.group("b"))
        if a is None and b is None:
            return (np.nan, np.nan)
        if a is None:
            return (b, b)
        if b is None:
            return (a, a)
        return (min(a, b), max(a, b))

    # å˜å€¤ï¼ˆæœ€åˆã«è¦‹ã¤ã‹ã£ãŸæ•°å€¤ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã†ï¼‰
    m = re.search(r"(\d+\.\dX|\dX|X|\d+(?:\.\d+)?)", s)
    if m:
        v = _x_token_to_value(m.group(1))
        if v is None:
            return (np.nan, np.nan)
        return (v, v)

    return (np.nan, np.nan)


def mean_from_range_series(series: pd.Series) -> pd.Series:
    mm = series.apply(lambda x: pd.Series(parse_range(x), index=["min", "max"]))
    # min,max ãŒã©ã£ã¡ã‹æ¬ ã‘ã¦ã‚‚å¹³å‡ãŒå–ã‚Œã‚‹ã‚ˆã†ã«ï¼ˆç‰‡æ–¹ã ã‘ãªã‚‰ãã®å€¤ï¼‰
    return mm[["min", "max"]].mean(axis=1, skipna=True)


def pct_vs(today: float, base: float) -> float:
    if pd.isna(today) or pd.isna(base) or base == 0:
        return np.nan
    return (today / base - 1.0) * 100.0


def fmt_pct(x: float) -> str:
    if pd.isna(x):
        return "NA"
    sign = "+" if x >= 0 else ""
    return f"{sign}{int(round(x))}%"


def extract_unit(text) -> str:
    """ '18-40 å°¾' -> 'å°¾'  '0.3-1.5kg' -> 'kg' ãªã©ã€‚å–ã‚Œãªã‘ã‚Œã°ç©º """
    if pd.isna(text):
        return ""
    s = _pre_normalize(str(text))
    # æ•°å­—/./-/X/ç©ºç™½ã‚’è½ã¨ã—ãŸæ®‹ã‚Šã‚’å˜ä½ã¨ã¿ãªã™ï¼ˆXã¯æ•°å€¤å´ã®è¨˜å·ãªã®ã§è½ã¨ã™ï¼‰
    s = re.sub(r"[\d\.\-\sX]", "", s)
    return s.strip()


def most_common_unit(series: pd.Series) -> str:
    units = [extract_unit(x) for x in series if not pd.isna(x)]
    units = [u for u in units if u not in {"", "ï¼", "-", "â€”", "â€•"}]
    if not units:
        return ""
    return Counter(units).most_common(1)[0][0]


def fmt_value_with_comp(value: float, unit: str, yoy: float, mom: float) -> str:
    # ä¾‹: 32å°¾ï¼ˆ+76% / +27%ï¼‰
    if pd.isna(value):
        return f"NAï¼ˆ{fmt_pct(yoy)} / {fmt_pct(mom)}ï¼‰"
    v = int(round(value))
    return f"{v}{unit}ï¼ˆ{fmt_pct(yoy)} / {fmt_pct(mom)}ï¼‰"


def pick_sheet(xls: pd.ExcelFile) -> str:
    for s in SHEET_CANDIDATES:
        if s in xls.sheet_names:
            return s
    return xls.sheet_names[0]


def normalize_kashimamaru(df_k: pd.DataFrame) -> pd.DataFrame:
    """
    kashimamaru ã‚·ãƒ¼ãƒˆã®åˆ—ï¼ˆä¾‹: æ—¥ä»˜, é‡£ã‚Šç‰©, æ•°é‡, å‹, å ´æ‰€, å‚™è€ƒï¼‰ã‚’
    all_fish äº’æ›ï¼ˆdate, fish_name, area_port, yado, choka, size, source, urlï¼‰ã«å¯„ã›ã‚‹
    """
    if df_k is None or df_k.empty:
        return pd.DataFrame(columns=["date", "fish_name", "area_port", "yado", "choka", "size", "source", "url"])

    # åˆ—åã‚†ã‚Œå¯¾ç­–ï¼ˆæœ€ä½é™ï¼‰
    colmap = {
        "æ—¥ä»˜": "date",
        "é‡£ã‚Šç‰©": "fish_name",
        "æ•°é‡": "choka",
        "å‹": "size",
        "å ´æ‰€": "area_port",
        "å‚™è€ƒ": "note",
    }
    df = df_k.rename(columns={k: v for k, v in colmap.items() if k in df_k.columns}).copy()

    # å¿…é ˆã®æ¬ ã‘ã¯ç©ºã§ä½œã‚‹
    for c in ["date", "fish_name", "choka", "size", "area_port"]:
        if c not in df.columns:
            df[c] = np.nan

    df["yado"] = "é¹¿å³¶ä¸¸"
    df["source"] = "kashimamaru"

    # URLã¯å›ºå®šã§å…¥ã‚Œã¦ãŠãï¼ˆãƒªãƒ³ã‚¯ä¸è¦ãªã‚‰ç©ºã§ã‚‚OKï¼‰
    # run_daily å´ã§ä¿å­˜ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã“ã“ã§ä»˜ä¸
    df["url"] = "https://www.aqualine.jp/kashimamaru/"  # å¤‰æ›´ã—ãŸã‘ã‚Œã°ã“ã“ã ã‘

    # å½¢å¼ã‚’ all_fish ã¨æƒãˆã‚‹
    keep = ["date", "fish_name", "area_port", "yado", "choka", "size", "source", "url"]
    df = df[keep].copy()

    # area_port ã¯ funaduri ãŒã€Œåœ°åŸŸ / æ¸¯ã€å½¢å¼ãªã®ã§ã€é¹¿å³¶ä¸¸ã¯ã€Œé¹¿å³¶ä¸¸ / å ´æ‰€ã€ã«å¯„ã›ã‚‹
    df["area_port"] = df["area_port"].astype(str).where(df["area_port"].notna(), "")
    df["area_port"] = df["area_port"].apply(lambda x: f"é¹¿å³¶ä¸¸ / {x}".strip(" /") if x and x != "nan" else "é¹¿å³¶ä¸¸")

    return df


def is_tachiuo_fishname(name: str) -> bool:
    if not isinstance(name, str):
        return False
    n = name.strip()
    return n in TACHIUO_NAMES or ("ã‚¿ãƒã‚¦ã‚ª" in n) or ("å¤ªåˆ€é­š" in n)


def main() -> None:
    if not SRC.exists():
        raise FileNotFoundError(f"Source file not found: {SRC}")

    xls = pd.ExcelFile(SRC)

    # ===== all_fish èª­ã¿è¾¼ã¿ =====
    sheet = pick_sheet(xls)
    df = pd.read_excel(SRC, sheet_name=sheet)

    # å¿…é ˆåˆ—ï¼ˆã‚ãªãŸã®å®Ÿãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ç¢ºå®šï¼‰
    required = {"date", "fish_name", "area_port", "yado", "choka", "size"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"Missing columns in sheet '{sheet}': {missing}")

    # ===== kashimamaru èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°æ··ãœã‚‹ï¼‰ =====
    if SHEET_KASHI in xls.sheet_names:
        df_k_raw = pd.read_excel(SRC, sheet_name=SHEET_KASHI)
        df_k = normalize_kashimamaru(df_k_raw)
        # all_fish ã¨åŒã˜åˆ—ã¸ï¼ˆå­˜åœ¨ã—ãªã„åˆ—ã¯è¿½åŠ ï¼‰
        for c in ["source", "url"]:
            if c not in df.columns:
                df[c] = ""
        df = df[["date", "fish_name", "area_port", "yado", "choka", "size", "source", "url"]].copy()
        df = pd.concat([df, df_k], ignore_index=True)
    else:
        # ãªã„å ´åˆã§ã‚‚ detail å‡ºåŠ›åˆ—ãŒæƒã†ã‚ˆã†ã«
        if "source" not in df.columns:
            df["source"] = ""
        if "url" not in df.columns:
            df["url"] = ""

    # æ—¥ä»˜æ•´å½¢
    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
    df = df.dropna(subset=["date", "fish_name", "yado", "area_port"])

    # ãƒ¬ãƒ³ã‚¸ä¸­å¤®ï¼ˆä»£è¡¨å€¤ï¼‰
    df["choka_mean"] = mean_from_range_series(df["choka"])
    df["size_mean"] = mean_from_range_series(df["size"])

    # ã€Œä»Šæ—¥ã€= ãƒ‡ãƒ¼ã‚¿ä¸­ã®æœ€æ–°æ—¥
    today = df["date"].max()
    if pd.isna(today):
        raise ValueError("No valid dates found.")

    # éå»çª“ï¼ˆä»Šæ—¥ã‚’å«ã‚ãªã„ï¼‰
    start_month = today - timedelta(days=WINDOW_MONTH)
    start_year = today - timedelta(days=WINDOW_YEAR)

    df_today = df[df["date"] == today].copy()
    df_month = df[(df["date"] < today) & (df["date"] >= start_month)].copy()
    df_year = df[(df["date"] < today) & (df["date"] >= start_year)].copy()

    # =========================
    # A) ä¸»è¦æŒ‡æ¨™ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆéš»æ•°é †ï¼‰
    # =========================
    unit_today = (
        df_today.groupby("fish_name")
        .agg(
            catch_unit=("choka", most_common_unit),
            size_unit=("size", most_common_unit),
        )
        .reset_index()
    )

    g_today = (
        df_today.groupby("fish_name")
        .agg(
            records=("fish_name", "size"),
            choka_today=("choka_mean", "mean"),
            size_today=("size_mean", "mean"),
        )
        .reset_index()
    )

    g_month = (
        df_month.groupby("fish_name")
        .agg(choka_month=("choka_mean", "mean"), size_month=("size_mean", "mean"))
        .reset_index()
    )
    g_year = (
        df_year.groupby("fish_name")
        .agg(choka_year=("choka_mean", "mean"), size_year=("size_mean", "mean"))
        .reset_index()
    )

    out = (
        g_today.merge(g_month, on="fish_name", how="left")
        .merge(g_year, on="fish_name", how="left")
        .merge(unit_today, on="fish_name", how="left")
    )

    out["choka_yoy"] = out.apply(lambda r: pct_vs(r["choka_today"], r["choka_year"]), axis=1)
    out["choka_mom"] = out.apply(lambda r: pct_vs(r["choka_today"], r["choka_month"]), axis=1)
    out["size_yoy"] = out.apply(lambda r: pct_vs(r["size_today"], r["size_year"]), axis=1)
    out["size_mom"] = out.apply(lambda r: pct_vs(r["size_today"], r["size_month"]), axis=1)

    out["catch_cell"] = out.apply(
        lambda r: fmt_value_with_comp(r["choka_today"], r.get("catch_unit", "") or "", r["choka_yoy"], r["choka_mom"]),
        axis=1,
    )
    out["size_cell"] = out.apply(
        lambda r: fmt_value_with_comp(r["size_today"], r.get("size_unit", "") or "", r["size_yoy"], r["size_mom"]),
        axis=1,
    )

    table = out[["fish_name", "records", "catch_cell", "size_cell"]].copy()
    table = table.sort_values(["records", "fish_name"], ascending=[False, True])

    # =========================
    # B) ã‚µãƒãƒªãƒ¼ï¼šé­šç¨®å†…ã§çªå‡ºã—ãŸèˆ¹ TOP5
    # =========================
    fish_mean_today = df_today.groupby("fish_name")["choka_mean"].mean()

    df_top = df_today.copy()
    df_top["fish_mean"] = df_top["fish_name"].map(fish_mean_today)
    df_top["vs_others_pct"] = (df_top["choka_mean"] / df_top["fish_mean"] - 1.0) * 100.0

    fish_counts = df_today.groupby("fish_name")["fish_name"].size()
    valid_fish = fish_counts[fish_counts >= MIN_RECORDS_FOR_TOP5].index
    df_top = df_top[df_top["fish_name"].isin(valid_fish)]

    idx = df_top.groupby("fish_name")["vs_others_pct"].idxmax()
    df_top_best_each_fish = df_top.loc[idx].copy()

    df_top5 = df_top_best_each_fish.sort_values("vs_others_pct", ascending=False).head(5)

    # =========================
    # B-2) ã‚¿ãƒã‚¦ã‚ªé™å®šãƒ©ãƒ³ã‚­ãƒ³ã‚° TOP5ï¼ˆé¹¿å³¶ä¸¸å«ã‚€ï¼‰
    # =========================
    df_tachiuo = df_today[df_today["fish_name"].apply(is_tachiuo_fishname)].copy()
    if not df_tachiuo.empty:
        t_mean = df_tachiuo["choka_mean"].mean()
        df_tachiuo["fish_mean"] = t_mean
        df_tachiuo["vs_others_pct"] = (df_tachiuo["choka_mean"] / df_tachiuo["fish_mean"] - 1.0) * 100.0
        df_tachiuo_top5 = df_tachiuo.sort_values("choka_mean", ascending=False).head(5)
    else:
        df_tachiuo_top5 = df_tachiuo

    # =========================
    # C) å±¥æ­´CSVï¼ˆä»»æ„ï¼‰
    # =========================
    HISTORY_CSV.parent.mkdir(parents=True, exist_ok=True)
    daily_metrics = out[["fish_name", "records", "choka_today", "size_today"]].copy()
    daily_metrics.insert(0, "date", today)
    if HISTORY_CSV.exists():
        hist = pd.read_csv(HISTORY_CSV)
        hist = hist[hist["date"] != str(today)]
        hist = pd.concat([hist, daily_metrics], ignore_index=True)
        hist.to_csv(HISTORY_CSV, index=False)
    else:
        daily_metrics.to_csv(HISTORY_CSV, index=False)

    # =========================
    # Markdown å‡ºåŠ›
    # =========================
    OUT_MD.parent.mkdir(parents=True, exist_ok=True)

    md: list[str] = []
    md.append("# ğŸ“Š Daily Fish Report")
    md.append(f"**{today}**")
    md.append("")

    md.append("## ğŸ“ ã‚µãƒãƒªãƒ¼")
    md.append("")
    md.append("### ğŸ† ä»Šæ—¥ã®â€œé­šç¨®å†…çªå‡ºèˆ¹â€ TOP5")
    if len(df_top5) == 0:
        md.append("- ï¼ˆæœ¬æ—¥ã¯æ¯”è¼ƒå¯èƒ½ãªé­šç¨®ï¼ˆéš»æ•°>=3ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")
    else:
        for i, r in enumerate(df_top5.itertuples(index=False), start=1):
            fish = r.fish_name
            boat = r.yado
            loc = r.area_port
            catch_unit = extract_unit(r.choka)
            catch_val = int(round(r.choka_mean)) if not pd.isna(r.choka_mean) else None
            pct = fmt_pct(r.vs_others_pct)
            if catch_val is None:
                md.append(f"{i}. **{boat}**ï¼ˆ**{loc}**ï¼‰â€” {fish} NAï¼ˆä»–èˆ¹å¯¾æ¯” {pct}ï¼‰")
            else:
                md.append(f"{i}. **{boat}**ï¼ˆ**{loc}**ï¼‰â€” {fish} **{catch_val}{catch_unit}ï¼ˆä»–èˆ¹å¯¾æ¯” {pct}ï¼‰**")

    md.append("")
    md.append("## âš” ã‚¿ãƒã‚¦ã‚ªé™å®šãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    md.append("")
    md.append("### ğŸ¥‡ ä»Šæ—¥ã®ã‚¿ãƒã‚¦ã‚ªèˆ¹ TOP5ï¼ˆä¸­å¤®å€¤ï¼‰")
    if df_tachiuo_top5 is None or len(df_tachiuo_top5) == 0:
        md.append("- ï¼ˆæœ¬æ—¥ã¯ã‚¿ãƒã‚¦ã‚ªã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")
    else:
        # å‚è€ƒï¼šä»–èˆ¹å¯¾æ¯”ã¯ã€Œã‚¿ãƒã‚¦ã‚ªã®å¹³å‡ã€ã«å¯¾ã™ã‚‹æ¯”
        if df_tachiuo["fish_mean"].notna().any() if not df_tachiuo.empty else False:
            t_mean_val = df_tachiuo["fish_mean"].iloc[0]
        else:
            t_mean_val = np.nan

        for i, r in enumerate(df_tachiuo_top5.itertuples(index=False), start=1):
            boat = r.yado
            loc = r.area_port
            unit = extract_unit(r.choka)
            val = int(round(r.choka_mean)) if not pd.isna(r.choka_mean) else None
            pct = fmt_pct((r.choka_mean / t_mean_val - 1.0) * 100.0) if (val is not None and not pd.isna(t_mean_val) and t_mean_val != 0) else "NA"
            if val is None:
                md.append(f"{i}. **{boat}**ï¼ˆ**{loc}**ï¼‰â€” NAï¼ˆä»–èˆ¹å¯¾æ¯” {pct}ï¼‰")
            else:
                md.append(f"{i}. **{boat}**ï¼ˆ**{loc}**ï¼‰â€” **{val}{unit}ï¼ˆä»–èˆ¹å¯¾æ¯” {pct}ï¼‰**")

    md.append("")
    md.append("## ğŸ“Š ä»Šæ—¥ã®ä¸»è¦æŒ‡æ¨™ï¼ˆéš»æ•°é †ï¼‰")
    md.append("")
    md.append("| fish_name | éš»æ•° | é‡£æœï¼ˆå¹´ / æœˆï¼‰ | ã‚µã‚¤ã‚ºï¼ˆå¹´ / æœˆï¼‰ |")
    md.append("|---|---:|---|---|")
    for _, r in table.iterrows():
        md.append(f"| {r['fish_name']} | {int(r['records'])} | {r['catch_cell']} | {r['size_cell']} |")

    md.append("")
    md.append("<details>")
    md.append("<summary>ğŸ“Š è©³ç´°ï¼ˆä»Šæ—¥ã®å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰</summary>")
    md.append("")
    detail_cols = ["fish_name", "yado", "area_port", "choka", "size", "source", "url"]
    for c in detail_cols:
        if c not in df_today.columns:
            df_today[c] = ""
    detail = df_today[detail_cols].copy()
    md.append(detail.to_markdown(index=False))
    md.append("")
    md.append("</details>")
    md.append("")
    md.append(f"Source: `{SRC}` / sheet: `{sheet}`" + (f" + `{SHEET_KASHI}`" if SHEET_KASHI in xls.sheet_names else ""))

    OUT_MD.write_text("\n".join(md), encoding="utf-8")
    print(f"Wrote: {OUT_MD}")


if __name__ == "__main__":
    main()
